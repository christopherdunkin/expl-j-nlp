This repository contains a Jupyter Notebook in which we explore various methods for processing Japanese text, with a focus on sentiment analysis (though other tasks are considered as well).

In addition to the standard modules NumPy, scikit-learn, pandas, seaborn, and PyTorch, we also make use of [Voyager](https://github.com/spotify/voyager) (for nearest neighbour search), [MeCab](https://pypi.org/project/mecab-python3/) (for word segmentation), [scikit-optimize](https://scikit-optimize.github.io/stable/) (which we use for Bayesian optimisation), and [llama-cpp-python](https://github.com/abetlen/llama-cpp-python) (for local LLMs).
